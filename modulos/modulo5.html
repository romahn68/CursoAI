<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Módulo 5: Riesgos y Limitaciones</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header class="module-header">
        <a href="../index.html" class="back-link">Volver al Índice</a>
        <h1>Módulo 5: Riesgos y Limitaciones de la IA</h1>
    </header>

    <main>
        <div class="module-content">
            <p>A pesar de su enorme potencial, es fundamental conocer las limitaciones y riesgos de la IA para usarla de forma responsable.</p>
            <ul>
                <li><strong>Sesgos y Discriminación:</strong> Una IA aprende de los datos con los que se la entrena. Si los datos reflejan prejuicios existentes en la sociedad (raciales, de género, etc.), la IA los aprenderá y los perpetuará. Por ejemplo, un sistema de contratación entrenado con datos históricos podría preferir candidatos masculinos si en el pasado la mayoría de contratados lo fueron.</li>
                <li><strong>Privacidad:</strong> Muchos sistemas de IA, especialmente los asistentes de voz o las redes sociales, recopilan enormes cantidades de datos personales. Esto plantea preguntas importantes sobre quién tiene acceso a esos datos y para qué se utilizan.</li>
                <li><strong>Desinformación y "Deepfakes":</strong> La capacidad de la IA para generar texto, imágenes y vídeos realistas puede usarse para crear noticias falsas o vídeos manipulados ("deepfakes") muy convincentes, lo que representa un riesgo para la confianza y la democracia.</li>
                <li><strong>"Caja Negra":</strong> A veces, ni siquiera sus creadores pueden explicar al 100% por qué un modelo de Deep Learning ha tomado una decisión concreta. Esta falta de transparencia (el efecto "caja negra") es un problema en campos donde la explicabilidad es crítica, como en la medicina.</li>
                <li><strong>El Rol Humano:</strong> Es crucial recordar que la IA es una herramienta. La supervisión, el juicio crítico y la ética humana deben ser siempre la última palabra.</li>
            </ul>
        </div>
    </main>

    <nav class="module-nav">
        <a href="modulo4.html" class="nav-link prev">← Módulo Anterior</a>
        <a href="modulo6.html" class="nav-link next">Siguiente Módulo →</a>
    </nav>

    <script src="../script.js"></script>
</body>
</html>
